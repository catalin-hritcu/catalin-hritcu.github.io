[INCLUDE=presentation]
Title         : Formally Secure Compartmentalizing Compilation
Author        : Catalin Hritcu
Affiliation   : Inria Paris
Reveal Url    : ../reveal.js
Reveal Theme  : white
Colorizer     : text
Logo          : False
Html Header   :
    <script src="../../stuff/script.js"></script>
    <link rel="stylesheet" href="../../stuff/style.css" id="custom_style">
Package       : xypic
HTML Meta     : clear
~Pre,~Code: language=text
Package       : tikz
Package       : mathtools
Tex Header    : \usetikzlibrary{decorations.shapes%
                               ,decorations.pathmorphing}
Toc Depth     : 2

~ MathDefs
[INCLUDE=../../stuff/latex.tex]
~

[//]: <> ( Madoko works poorly with Firefox, but nothing we can do about that )

[//]: <> (TODO P2: Maybe Switch to latest working Reveal.js ? One can set it like this:)
[//]: <> (Reveal Url    : https://cdn.jsdelivr.net/reveal.js/2.6.2 )
[//]: <> (Problem: main font of the slides changes to inferior one)

[//]: <> (TODO "P" is currently very overloaded: )
[//]: <> (- partial program P )
[//]: <> (- program identifier P (or C) â€“ could use some different "unicode font" for this? )
[//]: <> (    ğ‚ and ğ—£, â’¸ and â“…, ğ“’ and ğ“Ÿ, ... https://yaytext.com/double-struck/)
[//]: <> (- procedure identifier â„‚.P â€“ rename this to â„‚.p! )

[//]: <> (TODO Why not use K for components to distinguish them from a contexts? ğ•‚ := â„‚ | â„™ )

[//]: <> (MOSTLYFIXED Florian)
[//]: <> ( The current font doesn't look fixed width to me for the subscripts )
[//]: <> ( Probably those don't exist in the font I chose, and )
[//]: <> (  different people are seeing different font substitutions, )
[//]: <> (  only some of which are fixed width)
[//]: <> (- (Florian:) exactly, didn't find a font with all subscript glyphs with fixed width.)
[//]: <> (  Maybe evermono but it has a completely f'd up license (shareware 25â‚¬ and only 3 cpus for its use...)


# Formally Secure Compartmentalizing Compilation #

~Center

**[C&#259;t&#259;lin Hri&#355;cu, Inria Paris](http://prosecco.gforge.inria.fr/personal/hritcu/)**

[18th International School on Foundations of Security Analysis and Design (FOSAD)](http://www.sti.uniurb.it/events/fosad18/)

[Bertinoro, Italy](https://goo.gl/maps/oqzrpd6aMfr), 27-28 August 2018
~

[//]: <> (----------------------------------------------------------------------------)

[//]: <> ( # Formally Secure (Compartmentalizing) Compilation )
[//]: <> ( ## (1h) High-level vision )
[//]: <> ( Goals: )
[//]: <> ( - explain high-level story, outlining the rest of the course )
[//]: <> ( - impress and motivate, our work is cool, foundational, and practical )

[//]: <> ( Slides in PowerPoint )
[//]: <> ( - here is a draft: )
[//]: <> ( http://prosecco.gforge.inria.fr/personal/hritcu/talks/2018-08-26-Fomally-Secure-Compilation-FOSAD.pdf )

[//]: <> ( (DONE) Secure compilation is something even broader )
[//]: <> ( - the broader thing explained in the Dagstuhl report and talk: )
[//]: <> ( http://prosecco.gforge.inria.fr/personal/hritcu/talks/2018-05-14-Secure-Compilation-Goals-and-Attackers-Dagstuhl.pdf )
[//]: <> ( - this course is focused on formally secure compartmentalizing compilation )

[//]: <> ( (DONE) Secure compilation is not just about )
[//]: <> ( - devising formal criteria )
[//]: <> ( but also about )
[//]: <> ( - devising efficient enforcement mechanisms )
[//]: <> ( - devising effective proof / verification techniques )

[//]: <> ( WONTFIX: Are too much duplication or spoilers between this part )
[//]: <> (                 and the rest a problem? Is so how to deal with it? )
[//]: <> ( - try to stay as high-level as possible here )
[//]: <> ( - WONTFIX? try to leave out too advanced topics, like: )
[//]: <> (   + where is full abstraction, they won't know what that means )
[//]: <> (   + Do I want to explain the open problems so early? Why not? Could return to them too! )

# Content

[TOC]

# Correct compilation

## What's a compilation chain? (formally)
- **Source language**
- **Target language**
- **Compiler**
- {.fragment} Soon will also add: **Linker**!
- {.fragment} **Security enforcement can happen at all these levels**:
  + source language can have nice abstractions
  + target language (machine) can include loader,
    operating system support, cool hardware features, etc
  + compiler can do static analysis or insert security checks
  + {.fragment} **so we call it "secure compilation", not just "secure compilers"**

## Source language
- whole programs: `Wâ‚›`
- trace-based operational semantics: `Wâ‚› â‡ t`
- real-world examples: Pascal, Rust, Java, C#, ML, Haskell, ...
- {.fragment} simplifying away details: well-formedness of programs (e.g. typing)

## Target language
- whole programs: `Wâ‚œ`
- trace-based operational semantics: `Wâ‚œ â‡ t`
- real-world examples: ASM (x86, ARM, RISC-V), JVM, CIL, LLVM IR, ...
- {.fragment} simplifying assumption: exactly the same traces as for source

## Compiler
- a partial (math) function "`â†“`": `Wâ‚›â†“ = Wâ‚œ`
  + from whole source programs (`Wâ‚›`) to whole target programs (`Wâ‚œ`)
- {.fragment} verified compilers are defined as such partial functions:
  + CompCert is a function in Coq
  + CakeML is a function in HOL
- {.fragment} real-world more complicated: rustc, javac, ocamlc, ghc, ...

## Simple compilation chain

### (running example)

## Simple source language: PROC
Imperative language with procedures
```
e ::= i                       integer value
    | x                       variable lookup (for now global)
    | x := e                  variable assignment (for now global)
    | eâ‚ âŠ— eâ‚‚                 binary operations
    | eâ‚; eâ‚‚                  sequence
    | if eâ‚ then eâ‚‚ else eâ‚ƒ   conditional (tests if eâ‚ is non-zero)
    | P(e)                    procedure call
    | arg                     read the current procedure's argument
    | exit                    terminate

D ::= P(arg) { e }            procedure declaration

W ::= Dâ‚,...,Dâ‚™               whole program (where main(arg) { e } âˆˆ W)
```

## PROC operational semantics
```
W âŠ¢ M, x                     â†’  M, M[x]
W âŠ¢ M, x:=i                  â†’  M[xâ†¦i], i
W âŠ¢ M, iâ‚âŠ—iâ‚‚                 â†’  M, âŠ—(iâ‚,iâ‚‚)
W âŠ¢ M, i;eâ‚‚                  â†’  M, eâ‚‚
W âŠ¢ M, if i then eâ‚‚ else eâ‚ƒ  â†’  M, eâ‚‚  when i â‰  0
W âŠ¢ M, if 0 then eâ‚‚ else eâ‚ƒ  â†’  M, eâ‚ƒ
W âŠ¢ M, P(i)                  â†’  e[argâ†¦i]  when P(arg) { e } âˆˆ W
```
~Fragment
```
E ::=                 evaluation contexts (expressions with a hole [])
    [] | x := E | E âŠ— eâ‚‚ | iâ‚ âŠ— E | E; eâ‚‚ | if E then eâ‚‚ else eâ‚ƒ | P(E)

W âŠ¢ Mâ‚, eâ‚ â†’ Mâ‚‚, eâ‚‚
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
W âŠ¢ Mâ‚, E[eâ‚] â†’ Mâ‚‚, E[eâ‚‚]

W âŠ¢ M, E[exit] â†’ M, exit
```
~
~Fragment
```
InitS(W) = W âŠ¢ [xâ†¦0|x], main(0)          initial state for W
W âŠ¢ M, i and W âŠ¢ M, exit                 final states
```
~

## Events and traces: PROC+IO
```
e ::= ... | input | output e          external input and output

W âŠ¢ M, input    â†’_{Input i}  M, i
W âŠ¢ M, output i â†’_{Output i} M, i
```
~Fragment
```
Î± ::=                     events
    | Ï„                     silent event (mÂ·Ï„=m)
    | Input i               visible input
    | Output i              visible output

t ::=                     traces
    | Î±â‚Â·...Â·Î±â‚™Â·Done        succesful termination
    | Î±â‚Â·...Â·Î±â‚™Â·Loop        silent divergence
    | Î±â‚Â·...Â·Î±â‚™Â·...         infinite trace
```
~
~Fragment
```
W â‡ t â‰œ (âˆƒsf. âˆƒm finite, InitS(W) â†’*_t âˆ§ t = mÂ·Done sf âˆ§ sf final)
            âˆ¨ (âˆƒm finite. InitS(W) â†’Ï‰_t âˆ§ t = mÂ·Loop âˆ§ execution infinite)
                       âˆ¨ (InitS(W) â†’Ï‰_t âˆ§ t infinite âˆ§ execution infinite)
```
~

## Simple target language: REG+IO
Abstract machine with registers
```
instr ::= Nop                     do nothing
        | Halt                    terminate the program
        | Jal l                   direct jump-and-link
        | Jump r                  indirect jump to address in r
        | Bnz r l                 direct jump if r is non-zero
        | Label l                 declare code label (direct jump target)
        | Const i -> rd           put constant i in register
        | Copy rs -> rd           write value of rs to rd
        | BinOp râ‚ âŠ— râ‚‚ -> rd     write result of râ‚ âŠ— râ‚‚ to rd
        | Load *rp -> rd          dereference rp and put result in rd
        | Store rs -> *rp         write value in rs to addres in rp
        | Input rd                external input
        | Output rs               external output

Wâ‚œ ::= instrâ‚,...,instrâ‚™           (where no label is defined twice,
                                   and all used labels are defined)
```

## REG+IO operational semantics
```
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R, PC+1                     when Wâ‚œ[PC] = Nop
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R[R_RAâ†¦PC+1], offset_of(Wâ‚œ,l) when Wâ‚œ[PC] = Jal l,
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R, R[r]                     when Wâ‚œ[PC] = Jump r
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R, offset_of(Wâ‚œ,l)           when Wâ‚œ[PC] = Bnz r l and R[r] â‰  0
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R, PC+1                     when Wâ‚œ[PC] = Bnz r l and R[r] = 0
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R, PC+1                     when Wâ‚œ[PC] = Label l
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R[rdâ†¦i], PC+1               when Wâ‚œ[PC] = Const i -> rd
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R[rdâ†¦R[rs]], PC+1           when Wâ‚œ[PC] = Copy rs -> rd
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R[rdâ†¦âŠ—(R[râ‚],R[râ‚])], PC+1  when Wâ‚œ[PC] = BinOp râ‚ âŠ— râ‚‚ -> rd
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M, R[rdâ†¦M[R[rp]]], PC+1        when Wâ‚œ[PC] = Load *rp -> rd
Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M[R[rp]â†¦R[rs]], R, PC+1        when Wâ‚œ[PC] = Store rs -> *rp
Wâ‚œ âŠ¢ M, R, PC â†’_{Input i} M, R[rdâ†¦i], PC+1      when Wâ‚œ[PC] = Input rd
Wâ‚œ âŠ¢ M, R, PC â†’_{Output R[rs]} M, R, PC+1       when Wâ‚œ[PC] = Output rs
```
~Fragment
```
InitS(Wâ‚œ) = Wâ‚œ âŠ¢ [addrâ†¦0 | addr], [râ†¦0 | r], 0     initial states
Wâ‚œ âŠ¢ M, R, PC final if Wâ‚œ[PC] = Halt               final states
                    or Wâ‚œ[PC] not defined
```
~

~Fragment
Simplifications: infinite memory+integers, programs not stored in memory
~

[//]: <> ( Note: the operational semantics initializes all memory to 0 )
[//]: <> ( (alternatively, the compiler would have to initialize )
[//]: <> ( the memory storing variables) )

## Simple compiler: PROC+IO to REG+IO

[//]: <> ( Original Reference from Jeremy and Carmine: )
[//]: <> (  https://drive.google.com/file/d/1mfExQ0eiqWpDTte0CQxK1d4RtKH8cHPQ/view?usp=sharing  )

- Simple compiler uses 6 registers:
  + `R_Res` contains results of previous expression
  + `R_Aux` used as an auxiliary
  + `R_One` contains 1
  + `R_Arg` used to pass arguments to functions
  + `R_RA` stores return address
  + `R_SP` stores stack pointer

- {.fragment} Memory layout:
  + addresses `0,...,n-1` store variables
  + addresses `n,...    ` store a stack

## Compilation of expressions
```
iâ†“ = Const i -> R_Res
xâ†“ = Const addr_of(x) -> R_Aux; Load *R_Aux -> R_Res
(x := e)â†“ = eâ†“; Const addr_of(x) -> R_Aux; Store R_Res -> *R_Aux
(eâ‚ âŠ— eâ‚‚)â†“ = eâ‚â†“; Push R_Res; eâ‚‚â†“; Pop R_Aux; BinOp R_Res âŠ— R_Aux -> R_Res
(eâ‚; eâ‚‚)â†“ = eâ‚â†“; eâ‚‚â†“
(if eâ‚ then eâ‚‚ else eâ‚ƒ)â†“ = eâ‚â†“; Bnz R_Res lâ‚;
                                eâ‚ƒâ†“; Bnz R_One lâ‚‚;
                                Label lâ‚; eâ‚‚â†“;
                          Label lâ‚‚
P(e)â†“ = If declared(P) Then
          eâ†“; Push R_Arg; Push R_RA; Copy R_Res -> R_Arg; Jal label_of(P);
              Pop R_RA; Pop R_Arg
        Else
          Error "Call to undeclared procedure P"
argâ†“ = Copy R_Arg -> R_Res
exitâ†“ = Halt
inputâ†“ = Input R_Res
(output e)â†“ = eâ†“; Output R_Res
```

## The rest of the compiler

- Compilation of procedure declaration:
```
(P(arg) { e })â†“ = Label label_of(P); eâ†“; Jump R_RA
```

- {.fragment} Stack management
```
Push r = Store r -> *R_SP; BinOp R_SP + R_One -> R_SP
Pop r = BinOp R_SP - R_One -> R_SP; Load *R_SP -> r
```

- {.fragment} Compilation of whole program `W = Dâ‚,...,Dâ‚™`:
```
Wâ†“ = Const 1 -> R_One; Const |vars(W)| -> R_SP;
     Jal label_of(main); Halt; Dâ‚â†“; ...; Dâ‚™â†“
```

## Exercise: add while loop
- Extend the compilation chain with a while loop

~ Fragment
- Solution:

```
e := ... | while eâ‚ do eâ‚‚

E ::= ... | while E do eâ‚‚

W âŠ¢ M, while 0 do eâ‚‚ â†’ M, 0
W âŠ¢ M, while i do eâ‚‚ â†’ M, (eâ‚‚; while i do eâ‚‚)  when i â‰  0

(while eâ‚ do eâ‚‚)â†“ = Label lâ‚; eâ‚â†“; Bnz R_Res lâ‚‚; Bnz R_One lâ‚ƒ;
                                   Label lâ‚‚; eâ‚‚â†“; Bnz R_One lâ‚;
                                   Label lâ‚ƒ
```
~

[//]: <> ( (TODO P2 (Catalin): to be kept private; have code for that in F* tutorial) )

## Backward Correct Compilation (BCC)

- BCC: `âˆ€W t. Wâ†“ â‡ t  â‡’  W â‡ t`
  + intuitively `t` is a bad attack trace

- {.fragment} BCC defined in terms of traces of coarse-grained events
  - {.fragment} striking a pragmatic balance between:
    + the properties one can express and preserve
    + the optimizations the compiler can perform
  - {.fragment} example: making `Ï„` actions observable would be a disaster!
    + compiler would have to preserve number of reduction steps
    + can't build a compiler at all, even less an efficient one

## BCC â‡” Trace Property Preservation (TP)
- TP: `âˆ€W Ï€. W sat Ï€  â‡’  Wâ†“ sat Ï€`
  - where `Ï€` is a trace property:
    + i.e. property on traces
    + i.e. a set of accepted traces (`Ï€ âˆˆ 2^Trace`)
  - and `W sat Ï€ â‰œ âˆ€t. W â‡ t  â‡’  t âˆˆ Ï€`
- {.fragment} TP (property-full) = what we want: source-level reasoning
- {.fragment} BCC(property-free) = how to prove it: mapping traces

## Example trace properties

- $\pi_{\square\lnot\alpha} = \{t ~|~ \alpha \not\in t \}$
  - program should never cause bad event $\alpha$
  [//]: <> ( - real world example: avoid errors, outputing sensitive data, etc. )

- {.fragment} $\pi_{\square\lnot \mathtt{Done}}= \{t ~|~ \mathtt{Done} \not\in t\}$
  - program should not terminate
  [//]: <> ( - real world example: systems that must perform continuously )

- {.fragment} $\pi_{\lozenge\alpha} = \{ t ~|~ \alpha \in t \}$
  - program should eventually cause the good event $\alpha$
  [//]: <> ( - real world example: eventual termination (not sure of this) )

## Counterexamples to BCC

[//]: <> ( TODO: We went much overboard with the # of counterexamples here. )
[//]: <> (       Should focus on a few best ones ) )

## Example: Bad compilation #1

- Q: What happens if we don't Push and Pop on procedure calls?
- {.fragment} A: Register cluttering, wrong results.

- {.fragment} Example: Consider the program
```
W = main(arg) { P(1); output(arg) }; P(arg) { 1 }
```
  Then, if the compiler doesn't push/pop on calls:
```
Wâ†“ = Const 1 -> R_One; Const |vars(W)| -> R_SP; Jal label_of(main); Halt;
     Label label_of(main); Const 1 -> R_Res; Copy R_Res -> R_Arg; Jal label_of(P);
                           Copy R_Arg -> R_Res; Output R_Res; Jump R_RA;
     Label label_of(P); Const 1 -> R_Res; Jump R_RA
```
Trace: `t = Output 1; Output 1; Output 1; Output 1; ...`
but this is not an acceptable trace of the source program.

## Exercise: Bad compilation #2

- Q: What happens if we don't Push and Pop on binary operations?
- {.fragment} A: Register cluttering, wrong results.
  [//]: <> ( + Q: Is there any clever way to compile arithmetic expression )
  [//]: <> (      without a stack? What would Xavier do? )
  [//]: <> (   A: For DSSS'17 Xavier uses a stack machine. )
```
W = main(arg) { output(2 + (1 + 1)) }
```
  Can only do the trace
`t = output(4)`
```
Wâ†“ = Const 1 -> R_One; Const |vars(W)| -> R_SP; Jal label_of(main); Halt;
     Label label_of(main); Const 2 -> R_Res; Copy R_Res -> R_Aux;
       Const 1 -> R_Res; Copy R_Res -> R_Aux; Const 1 -> R_Res;
       BinOp R_Res + R_Aux -> R_Res;
       BinOp R_Res + R_Aux -> R_Res
```
  The compiled program can only have trace `t = Output 3`.

[//]: <> ( TODO (Jeremy): remove vertical scroll )

## Optimizations
- Q: Can we simplify `e+e` to `2*e`?
```
(eâ‚ âŠ— eâ‚‚)â†“ = If âŠ—=+ and eâ‚=eâ‚‚ Then (2 * eâ‚)â†“ Else ... as before ...
```
- {.fragment} A: Not always!
  + `output 2 + output 2` computes `4` with trace `Output 2;Output 2`
  + `2 * output 2` computes `4` with trace `Output 2`, this is different!
  + need static analysis to check whether e could have side-effects
  + memory write also side-effect:
    `(x++)+(x++)` not the same as `2*(x++)`

- {.fragment} Another example optimization:
  + Code without side-effects and whose result not used can be removed
  + e.g. `eâ‚; eâ‚‚` can be simplified to `eâ‚‚`,
    if `eâ‚` does no memory writes, no inputs, and no outputs

## Semantics mismatch
- We could make the semantics of `x:=i` return `0`. This alone breaks BCC.
```
W âŠ¢ M, x:=i â†’ M[xâ†¦i], 0
```
- {.fragment} Source expression `P = output (x:=5)` now has the trace `Output 0`.
- {.fragment} `Pâ†“` still has the trace `Output 5` though.
```
Pâ†“ = output(x:=5)â†“ = (x := 5)â†“; Output R_Res
= Const 5 -> R_Res; Const addr_of(x) -> R_Aux; Store R_Res -> *R_Aux; Output R_Res
```
- {.fragment} Q: How to solve this issue?
  + Modify the compiler:
```
    (x := e)â†“ = eâ†“; Const addr_of(x) -> R_Aux; Store R_Res -> *R_Aux; Const 0 -> R_Res
```
  + Change back the source semantics:
```
    W âŠ¢ M, x:=i â†’ M[xâ†¦i], i
```
  + Modify the target semantics (strange in this case):
```
    Wâ‚œ âŠ¢ M, R, PC â†’Ï„ M[R[rp]â†¦R[rs]], R[R_Resâ†¦0], PC+1  when Wâ‚œ[PC] = Store rs -> *rp
```
    still have to ensure this does not break anything else in the compiler

[//]: <> ( TODO: Would be nice to also have an example that uses inputs )
[//]: <> (       and thus has one than one trace )

[//]: <> ( TODO (Jeremy): our events are Input i and Output i  )


## BCC â‡’ TP proof (easy)
- BCC (know): `âˆ€W t. Wâ†“ â‡ t â‡’ W â‡ t`
- TP (show): `âˆ€W Ï€. W sat Ï€ â‡’ Wâ†“ sat Ï€`
  + where `W sat Ï€ â‰œ âˆ€t. W â‡ t â‡’ t âˆˆ Ï€`
  + and `Wâ†“ sat Ï€ â‰œ âˆ€t. Wâ†“ â‡ t â‡’ t âˆˆ Ï€`
- {.fragment} Let `W` and `Ï€` so that `W sat Ï€`.
- {.fragment} Let `t` so that `Wâ†“ â‡ t`.
- {.fragment} To show: `t âˆˆ Ï€`.
- {.fragment} By BCC from `Wâ†“ â‡ t` we get that `W â‡ t`.
- {.fragment} From definition of `W sat Ï€` we conclude that `t âˆˆ Ï€`.

## BCC â‡ TP proof (more interesting, still easy)
- TP (know): `âˆ€W Ï€. W sat Ï€ â‡’ Wâ†“ sat Ï€`
  + where `W sat Ï€ â‰œ âˆ€t. W â‡ t â‡’ t âˆˆ Ï€`
  + and `Wâ†“ sat Ï€ â‰œ âˆ€t. Wâ†“ â‡ t â‡’ t âˆˆ Ï€`
- BCC (show): `âˆ€W t. Wâ†“ â‡ t â‡’ W â‡ t`
- {.fragment} Let `W` be arbitrary. We need to show that `âˆ€t. Wâ†“ â‡ t â‡’ W â‡ t`
- {.fragment} We instantiate TP with `W` and `Ï€ = {t | W â‡ t}`
  + We can since `W sat Ï€` holds trivially: `âˆ€t. W â‡ t â‡’ W â‡ t`
- {.fragment} This gives us that `Wâ†“ sat Ï€ â‡” âˆ€t. Wâ†“ â‡ t â‡’ W â‡ t`. Qed.
- {.fragment} This simple proof thanks to Alix Trieu (Univ. Rennes)

## BCC often proved by simulation

- BCC can be proved by showing a **backwards simulation**\
  $s_t \to_a s_t' \wedge s_t \sim s_s \Rightarrow \exists s_s'.~ s_s \to_a s_s' \wedge s_t' \sim s_s'$
~ Snippet
\begin{tikzpicture}
\tikzstyle{all}= [draw, fill=blue!20,  minimum size=2em, rounded corners]
\tikzstyle{some}=[draw, fill=green!20, minimum size=2em, rounded corners]
\node[all]  (st)  at (0, 0) {$s_t$};
\node[all]  (st1) at (3, 0) {$s_t'$};
\node[all]  (ss)  at (0, 3) {$s_s$};
\node[some] (ss1) at (3, 3) {$\exists s_s'$};
\draw[->, blue,           thick, very near end, below=3em] (st) edge node {$a$} (st1);
\draw[->, black!60!green, thick, very near end, below=3em] (ss) edge node {$a$} (ss1);
% Large lengths don't seem to quite work
\draw[-, blue,           thick, decorate, decoration=snake, segment length=50] (ss)  -- (st);
\draw[-, black!60!green, thick, decorate, decoration=snake, segment length=50] (ss1) -- (st1);
\end{tikzpicture}
~
- {.fragment} leaving out `Ï„` transitions here, which add complications
[//]: <> ( TODO: It's exactly these left out steps that cause problems )
[//]: <> ( on the next slide )

## Backward simulations are hard to prove
- A single source expression often compiled to many machine instructions
- Have to look at the execution of many instructions before one can
  determine to what source expression it corresponded (decompilation)
- Optimizations can make this very difficult

## Forward simulation
- If languages are "well behaved" a **forward simulation** is enough:\
  $s_s \to_a s_s' \wedge s_t \sim s_s \Rightarrow \exists s_t'.~ s_t \to_a s_t' \wedge s_t' \sim s_s'$
~ Snippet
\begin{tikzpicture}
\tikzstyle{all}= [draw, fill=blue!20,  minimum size=2em, rounded corners]
\tikzstyle{some}=[draw, fill=green!20, minimum size=2em, rounded corners]
\node[all]  (st)  at (0, 0) {$s_t$};
\node[some] (st1) at (3, 0) {$\exists s_t'$};
\node[all]  (ss)  at (0, 3) {$s_s$};
\node[all]  (ss1) at (3, 3) {$s_s'$};
\draw[->, black!60!green, thick, very near end, below=3em] (st) edge node {$a$} (st1);
\draw[->, blue,           thick, very near end, below=3em] (ss) edge node {$a$} (ss1);
% Large lengths don't seem to quite work
\draw[-, blue,           thick, decorate, decoration=snake, segment length=50] (st)  -- (ss);
\draw[-, black!60!green, thick, decorate, decoration=snake, segment length=50] (st1) -- (ss1);
\end{tikzpicture}
~
- {.fragment} Theorem (trivial): If target is **deterministic** then forward simulation
  implies backward simulation.

## Determinism sufficient, not necessary

- Definition: We call a semantics `â‡` **determinate** if
```
Wâ‡tâ‚ âˆ§ Wâ‡tâ‚‚ âˆ§ tâ‚â‰ tâ‚‚ â‡’ âˆƒm aâ‚â‰ aâ‚‚. input aâ‚ âˆ§ input aâ‚‚ âˆ§ mÂ·aâ‚ â‰¤ tâ‚ âˆ§ mÂ·aâ‚‚ â‰¤ tâ‚‚
```
  + no internal nondeterminism, all nondeterminism via external inputs

- {.fragment} Definition: We call a semantics `â‡` **input total** (aka. receptive) if
```
input aâ‚ âˆ§ input aâ‚‚ âˆ§ W â‡*_{mÂ·aâ‚} â‡’ W â‡*_{mÂ·aâ‚‚}
```

- {.fragment} Theorem (Simplified from CompCert): If source is input total and
  target is determinate then forward simulation â‡’ backward simulation.
[//]: <> (  )
[//]: <> ( CompCert proof summarized in  )
[//]: <> ( <micro-policies-priv>/robust/compcert_events.txt )
[//]: <> ( but not simple enough to show )
[//]: <> (  )
[//]: <> ( TODO: Marco Vassena asked about "progress" (not getting stuck) )
[//]: <> ( assumptions on this kind of proof. I remember Xavier's course )
[//]: <> ( also had something about that, and Andrew's proof sketch too. )
[//]: <> ( Will need to double check on that! ) )

- {.fragment} You want to learn more about correct compilation?
  - Videos+materials of Xavier Leroy's DSSS'17 lectures are
    [available](https://deepspec.org/event/dsss17/lecture_leroy.html)
    [online](https://xavierleroy.org/courses/DSSS-2017/)

[//]: <> ( TODO: Would be a good exercise (for us at least) to redo all this course for a stack machine )
[//]: <> ( TODO: And to make it more real we could then port all this to target WebAssembly )

[//]: <> ( TODO: Finally, we could formalize the most interesting of these compilers in Coq, )
[//]: <> (       trying to keep things as simple and clean as possible. )
[//]: <> (       Maybe something to try with Arthur or Steven? )

## BCC is only about whole programs
- it doesn't allow separate compilation
- it doesn't allow linking with target code
  + even when that code is not malicious (e.g. verified)
- all correctness guarantees lost
- so let's first allow these easy cases
  (easier than secure compilation)

## 2-Linking and how it changes what a compiler chain is

- 2-Linking: Context + Partial Program = Whole Program
[//]: <> ( TODO repeated below )

- {.fragment} We extend both source and target with:
  - Two new syntactic categories:
    **contexts** (`C`) and **partial programs** (`P`)
  - Partial function to **link** C and P to produce a whole program W: C[P] = W
  - Compiler variants for **separately compiling** contexts and partial programs:
    Pâ‚›â†“ = Pâ‚œ and Câ‚›â†“ = Câ‚œ

- {.fragment} No constraints on what linking can do:
  - any of C and P can have initial control (e.g. define main), ...

## 2-Linking for our example
- Extending our source language (PROC+IO+2L):
  - {.fragment} `W ::= Dâ‚,...,Dâ‚™` â€“ where no procedure is defined twice,
     all used procedures are defined, and `main(arg) { e } âˆˆ Wâ‚›`
  - {.fragment} `P,Câ‚› ::= Dâ‚,...,Dâ‚™` â€“ where no procedure is defined twice
  - {.fragment} linking just concatenation (provided result is valid whole program):
```
    (Dâ‚,...,Dâ‚™)[Dâ‚',...,Dâ‚˜'] = Dâ‚,...,Dâ‚™, Dâ‚',...,Dâ‚˜'
```

- {.fragment} Extending our target language (REG+IO+2L):
  - `Wâ‚œ ::= instrâ‚;...;instrâ‚™` â€“ where no label is defined twice,
     and all used labels are defined
  - `Pâ‚œ,Câ‚œ ::= vars_no, instrâ‚;...;instrâ‚™` â€“ no label is defined twice
  - linking concatenation + adding preamble (provided result is valid):
```
    (vars_no, instrâ‚,...,instrâ‚™)[vars_no', instrâ‚',...,instrâ‚˜'] =
      Const 1 -> R_One; Const (vars_no + vars_no') -> R_SP;
      Jal label_of(main); Halt; instrâ‚;...;instrâ‚™;instrâ‚';...;instrâ‚˜'
```

## 2-Linking for our example (continued)
- Compilation for partial programs / contexts:
  - If `Câ‚› = Dâ‚,...,Dâ‚™` then `Câ‚›â†“ = |vars(Câ‚›)|, Dâ‚â†“; ...; Dâ‚™â†“`
  - If `P = Dâ‚,...,Dâ‚™` then `Pâ†“ = |vars(P)|, Dâ‚â†“; ...; Dâ‚™â†“`

[//]: <> ( TODO This slide is too short; just that it didn't fit on previous )

## Separate and Compositional Correct Compilation

- Separate Correct Compilation (SCC):
  `Câ‚›â†“[Pâ†“] â‡ t â‡’ Câ‚›[P] â‡ t`
  - This allows linking, but only with compiled contexts
    [//]: <> ( (i.e. not with arbitrary context built from the target language). )

- {.fragment} Compositional Correct Compilation (CCC):\
  `Câ‚œ â‰ˆ Câ‚› âˆ§ Câ‚œ[Pâ†“] â‡ t â‡’ Câ‚›[P] â‡ t`
  - This allows linking with target contexts, but only if we know that
    they behave like a source-level context
  - e.g. produced by compilation, manually optimized and verified, etc

[//]: <> ( TODO: This theorem I skipped, it's anyway too obious )
[//]: <> ( - {.fragment} Theorem: Assuming that `âˆ€Câ‚›. Câ‚›â†“ â‰ˆ Câ‚›` we have CCC â‡’ SCC. )
[//]: <> (   - Let P Câ‚› t so that Câ‚›â†“[Pâ†“] â‡ t. To show: Câ‚›[P] â‡ t )
[//]: <> (   - Since Câ‚›â†“ â‰ˆ Câ‚› we can apply CCC to obtain Câ‚›[P] â‡ t )

[//]: <> ( TODO This was too much for Bertinoro, but still interesting for future courses )
[//]: <> ( Separate compilation property: )
[//]: <> ( `âˆ€P Câ‚› t. Câ‚›â†“[Pâ†“] â‡ t â‡” (Câ‚›[P])â†“ â‡ t` )
[//]: <> ( + Whole program compilation of a linked source program should do the )
[//]: <> (   same as separate compilation followed by target linking )
[//]: <> ( + "separate compilation" property (later) holds syntactically for )
[//]: <> (   our compiler above: `Câ‚›â†“[Pâ†“] = (Câ‚›[P])â†“` )

[//]: <> ( <\!-- later diagram proof (rsc-diagram-bcc-fcc-reuse.png) will use )
[//]: <> (      separate compilation definition too! -\-> )

[//]: <> ( Theorem: Assuming that every whole program W can be split as some P and Câ‚› )
[//]: <> ( (realistic), separate compilation implies that SCC is the same as BCC. )
[//]: <> ( Proof: )
[//]: <> ( - SCC â‡’ BCC. Let W and t so that Wâ†“ â‡ t. To show: W â‡ t )
[//]: <> (   + by assumption âˆƒP Câ‚›, W = Câ‚›[P] )
[//]: <> (   + by separate compilation from Wâ†“ â‡ t we get Câ‚›â†“[Pâ†“] â‡ t )
[//]: <> (   + by SCC: Câ‚›[P] â‡ t so W â‡ t )
[//]: <> ( - BCC â‡’ SCC. Let Câ‚› P t so that Câ‚›â†“[Pâ†“] â‡ t. To show: Câ‚›[P] â‡ t )
[//]: <> (   + by separate compilation: (Câ‚›[P])â†“ â‡ t )
[//]: <> (   + by BCC: Câ‚›[P] â‡ t )

[//]: <> ( TODO (later): How does all this relate to Gil Hur's separate )
[//]: <> (               compilation work that got integrated in CompCert? ) )


[//]: <> ( under which assumption is the reverse true? )
[//]: <> ( - what if â‰ˆ is defined in terms of compilation, e.g. Câ‚› â‰ˆ Câ‚œ â‰œ Câ‚œ = Câ‚›â†“? )
[//]: <> (   then CCC becomes âˆ€P Câ‚› t. Câ‚›â†“[Pâ†“] â‡ t â‡’ Câ‚›[P] â‡ t, which is exactly SCC )
[//]: <> ( - this is an extreme kind of instantiation though! )

[//]: <> ( TODO (Catalin): more consistent notation in the past slides, )
[//]: <> (                 subscripts only for contexts )

## 2-Compartmentalized source language: PROC+IO+2â„‚

- PROC+IO+2L allows linking; we now extend this to components:
  - components have their own component-local variables
    + a source context Câ‚› cannot write the program P's variables
  - more informative events:
    + so that discussing about robust satisfaction makes sense
  - abstractions of PROC+IO+2L and earlier are still there
    + e.g. the call-return discipline is still enforced at this level

- {.fragment} PROC+IO+2â„‚ would be a good source for secure compilation chain

## PROC+IO+2â„‚ syntax
[//]: <> ( - New syntactic class to identify "C" or "P": )
```
â„‚ ::= "C" or "P"        component identifier
e ::= ...
    | x                 variables now interpreted per component (â„‚_cur.x)
      ...
    | â„‚.P(e)            call to component â„‚
    | return â„‚ e        return to component â„‚ after executing e

Câ‚›,P ::= Dâ‚,...,Dâ‚™       where no procedure is defined twice

W ::= C.Dâ‚,...,C.Dâ‚™, P.Dâ‚',...,P.Dâ‚˜'

Î± ::= ...               more informative events
    | Input â„‚ i           visible input from â„‚
    | Output â„‚ i          visible output from â„‚
```

- {.fragment} Source linking of `Câ‚› = Dâ‚,...,Dâ‚™` and `P = Dâ‚',...,Dâ‚˜'`\
  (we keep track which procedures come from `C` and which ones from `P`)
```
Câ‚›[P] â‰œ C.Dâ‚,...,C.Dâ‚™,P.Dâ‚',...,P.Dâ‚˜'
```

## PROC+IO+2â„‚ operational semantics:
- the variables of each component are fully separated from the others
  - we have to keep track of the current component â„‚ in the configuration

```
W âŠ¢ â„‚, M, x â†’Ï„ â„‚, M, M[â„‚,x]
W âŠ¢ â„‚, M, x:=i â†’ â„‚, M[â„‚,x â†¦ i], i
...
W âŠ¢ â„‚â‚, M, â„‚â‚‚.P(i) â†’Ï„ â„‚â‚‚, M, e[argâ†¦i]            when â„‚â‚‚.P(arg){e}âˆˆW and â„‚â‚=â„‚â‚‚
W âŠ¢ â„‚â‚, M, â„‚â‚‚.P(i) â†’Ï„ â„‚â‚‚, M, return â„‚â‚ e[argâ†¦i]  when â„‚â‚‚.P(arg){e}âˆˆW and â„‚â‚â‰ â„‚â‚‚
W âŠ¢ â„‚â‚‚, M, return â„‚â‚ i â†’Ï„ â„‚â‚, M, i
...
Wâ‚œ âŠ¢ â„‚, M, R, PC â†’_{Input â„‚ i} â„‚, M, R[rdâ†¦i], PC+1      when Wâ‚œ[PC] = Input rd
Wâ‚œ âŠ¢ â„‚, M, R, PC â†’_{Output â„‚ R[rs]} â„‚, M, R, PC+1       when Wâ‚œ[PC] = Output rs

E ::= ... | return â„‚ E

InitS(W) = W âŠ¢ â„‚, [â„‚,x â†¦ 0 | â„‚,x], main(0)  where â„‚.main(arg){e} âˆˆ W
```

## A correct but insecure compiler for PROC+IO+2â„‚
- We've just introduced one more source-level abstraction: components
- But a correct compiler can simply erase this abstraction going down
  [//]: <> ( (But a secure compiler has to enforce this abstraction.) )

- We can easily build a correct compiler from PROC+IO+2â„‚ to REG+IO+2L
  (BCC, SCC, CCC) that is not at all secure.

- {.fragment} Compiled program and context share the same memory space:
  - addresses `  0,...,n-1  ` store C's variables
  - addresses `  n,...,n+m-1` store P's variables
  - addresses `n+m,...      ` store a shared stack

~Fragment
```
(â„‚, x)â†“ = Const addr_of(â„‚,x) -> R_Aux; Load *R_Aux -> R_Res
(â„‚, x := e)â†“ = (â„‚, e)â†“; Const addr_of(â„‚,x) -> R_Aux; Store R_Res -> *R_Aux
```
~

## A correct but insecure compiler (continued)

- Calls and returns compiled as before using `Jal` and `Jump`:
```
(â„‚, â„‚.P(e))â†“ = (â„‚, e)â†“; Push R_Arg, R_RA; Copy R_Res -> R_Arg; Jal label_of(â„‚.P);
                        Pop R_RA, R_Arg
(â„‚.P(arg) { e })â†“ = Label label_of(â„‚.P); (â„‚, e)â†“; Jump R_RA
```

- {.fragment} Compilation for whole program `W = C.Dâ‚,...,C.Dâ‚™,P.Dâ‚',...,P.Dâ‚˜'`:
```
Wâ†“ = Const 1 -> R_One; Const |vars(W)| -> R_SP;
     Jal label_of(main); Halt; Dâ‚â†“; ...; Dâ‚™â†“; Dâ‚'â†“; ...; Dâ‚˜'
```
  - basically as before, erases to which component a procedure belongs

- {.fragment} Compilation for partial programs and contexts:
  - If `Câ‚› = Dâ‚,...,Dâ‚™` then `Câ‚›â†“ = |vars(Câ‚›)|, Dâ‚â†“; ...; Dâ‚™â†“`
  - If `P = Dâ‚,...,Dâ‚™` then `Pâ†“ = |vars(P)|, Dâ‚â†“; ...; Dâ‚™â†“`

[//]: <> ( TODO A lot of the last few was just repetition )

- {.fragment} Target linking:
```
(nv,instrâ‚;...;instrâ‚™)[mv,instrâ‚;...;instrâ‚˜] =
    Const 1 -> R_One; Const (nv+mv) -> R_SP;
    Jal label_of(main); Halt; instrâ‚;...;instrâ‚™;instrâ‚;...;instrâ‚˜
```

[//]: <> ( TODO This last one runs out of the slide )

## This compilation chain is correct but insecure

- This compilation chain satisfies BCC, SCC, CCC, so it is correct
  - it works if only using it for whole programs, or only linking with
    target contexts that are also compiled by â†“, or which behave as if they were

- {.fragment} This compilation chain is insecure if linking
  **arbitrary** target contexts:
  - target context can write program's variables (shared memory)
  - target context can smash the shared stack, corrupt temporaries and
    return addresses, change the shared `R_SP` register at will
  - target context can jump to any program code (not just entry points)
  - but, since code is still immutable, target context can't write
    program's code (hurrah! one single abstraction protected!)

## Correct compilation is not enough

- We want to allow linking with **arbitrary** target code:
  - interoperate with code written in other languages\
    (e.g. libraries, host application)
  - implement things that are not possible in a high-level language
  - that's the way compiler chains are already used today!

- {.fragment} But linking in target code naively is insecure
  - target contexts have a lot of power over the program,
  - linked low-level code that is malicious or compromised can blatantly
    violate most source-level abstractions

# Secure interoperability with lower-level code

[//]: <> ( Secure (2-Compartmentalizing) Compilation as Robust Property Preservation )

[//]: <> ( ## Motivation )
[//]: <> ( return to powerpoint slides 3 (lower half), 5, 6, 7 )
[//]: <> ( other useful slides here: 9-12 )
[//]: <> ( ... and even 13 at the end, or when switching to hyperproperties )
[//]: <> ( CH: enough duplication already, so no )

## Robust Trace Property Preservation (RTP)

- TP: `âˆ€W Ï€âˆˆ2^Trace. W sat Ï€ â‡’ Wâ†“ sat Ï€`
  - where `W sat Ï€ â‰œ âˆ€t. W â‡ t â‡’ t âˆˆ Ï€`

- {.fragment} RTP: `âˆ€P Ï€âˆˆ2^Trace. P robustly sat Ï€ â‡’  Pâ†“ robustly sat Ï€`
  - `P robustly sat Ï€ â‰œ âˆ€Câ‚›. Câ‚›[P] sat Ï€ = âˆ€Câ‚› t. Câ‚›[P]â‡t â‡’ tâˆˆÏ€`

- {.fragment} RTC: `âˆ€P Câ‚œ t. Câ‚œ[Pâ†“] â‡ t â‡’ âˆƒCâ‚›. Câ‚›[P] â‡ t`

- {.fragment} RTP = what we want: source-level security reasoning
- {.fragment} RTC = how to prove it: produce `Câ‚›` by "back-translating" `Câ‚œ[P]â‡t`

## RTP â‡ RTC (easy)
```
RTC (know): âˆ€P Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ âˆƒCâ‚›. Câ‚›[P]â‡t
RTP (show): âˆ€P Ï€. (âˆ€Câ‚› t. Câ‚›[P]â‡t â‡’ tâˆˆÏ€) â‡’ (âˆ€Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ tâˆˆÏ€)
```
+ {.fragment} Let `P` and `Ï€`, such that `âˆ€Câ‚› t. Câ‚›[P]â‡t â‡’ tâˆˆÏ€ (H)`
+ {.fragment} Let `Câ‚œ` and `t` such that `Câ‚œ[Pâ†“]â‡t`. To show: `tâˆˆÏ€`
+ {.fragment} by RTC get `âˆƒCâ‚›. Câ‚›[P]â‡t`
+ {.fragment} finally by instantiating (H) with `Câ‚›` and `t` we get `tâˆˆÏ€`

## RTP â‡’ RTC (Alix style, very simple)
```
RTP (know): âˆ€P Ï€. (âˆ€Câ‚› t. Câ‚›[P]â‡t â‡’ tâˆˆÏ€) â‡’ (âˆ€Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ tâˆˆÏ€)
RTC (show): âˆ€P Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ âˆƒCâ‚›. Câ‚›[P]â‡t
```
+ {.fragment} Let `P`. To show: `âˆ€Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ âˆƒCâ‚›. Câ‚›[P]â‡t`
+ {.fragment} Apply RTP with `P` and `Ï€={t|âˆƒCâ‚›. Câ‚›[P]â‡t}`.
  - we can, since `âˆ€Câ‚› t. Câ‚›[P]â‡t â‡’ âˆƒCâ‚›'. Câ‚›'[P]â‡t ` is trivially true
+ {.fragment} This gives us that `âˆ€Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ âˆƒCâ‚›. Câ‚›[P]â‡t`. Done.

## RTP â‡’ RTC (our old proof, a bit more complex)
```
RTP (know): âˆ€P Ï€. (âˆ€Câ‚› t. Câ‚›[P]â‡t â‡’ tâˆˆÏ€) â‡’ (âˆ€Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ tâˆˆÏ€)
          â‡” âˆ€P Ï€ Câ‚œ t. (Câ‚œ[Pâ†“]â‡t âˆ§ tâˆ‰Ï€) â‡’ âˆƒCâ‚› t'. (Câ‚›[P]â‡t' âˆ§ t'âˆ‰Ï€)
RTC (show): âˆ€P Câ‚œ t. Câ‚œ[Pâ†“]â‡t â‡’ âˆƒCâ‚›. Câ‚›[P]â‡t
```
+ {.fragment} Let `P`, `Câ‚œ` and `t` such that `Câ‚œ[Pâ†“]â‡t`. To show: `âˆƒCâ‚›. Câ‚›[P]â‡t`
+ {.fragment} Apply RTP contrapositive with `P`, `Câ‚œ`, `t`, and `Ï€={t'|t'â‰ t}`.
  - We can do this since `Câ‚œ[Pâ†“]â‡t` and `tâˆ‰Ï€`.
+ {.fragment} This gives us that `âˆƒCâ‚› t'. (Câ‚›[P]â‡t' âˆ§ t'âˆ‰Ï€)`
+ {.fragment} Observe that `t'âˆ‰Ï€` implies `t'=t`. So we are done.
  - {.fragment} Double negation elimination, `t'âˆ‰Ï€ â‡” Â¬(t'â‰ t) â‡” t'=t`

[//]: <> ( TODO No need to show this any more next time )


## Finite trace prefixes, formally
```
t ::=                     traces
    | Î±â‚Â·...Â·Î±â‚™Â·Done        succesful termination
    | Î±â‚Â·...Â·Î±â‚™Â·Loop        silent divergence
    | Î±â‚Â·...Â·Î±â‚™Â·...         infinite trace

m ::=                     finite trace prefixes
    | Î±â‚Â·...Â·Î±â‚™Â·Done        succesful termination
    | Î±â‚Â·...Â·Î±â‚™Â·Tbc         to be continued

m â‰¤ t                     prefix relation (inductive)

  Done â‰¤ Done         m â‰¤ t
                    â€”â€”â€”â€”â€”â€”â€”â€”â€”
  Tbc â‰¤ t           Î±Â·m â‰¤ Î±Â·t
```

## Finite trace prefixes, intuitively

- Capture the observations that can be made about an execution
  in finite time, e.g. by a reference monitor (crucial for defining safety properties)
  - monitor can observe that the program has terminated
  - monitor can't observe divergence or silent divergence

- {.fragment} Previous trace models with only infinite traces
  - standard for defining (hyper)properties for reactive system models
  - unrealistic for non-reactive programs: programs can't terminate

- {.fragment} Previous trace models with finitely observable termination
  - often used for defining full abstraction
  - but unrealistic for a reference monitor (safety properties)

## Safety properties
- $\mathtt{Safety} \triangleq \{\pi \in 2^\mathtt{Trace} ~|~ \forall t\not\in\pi.~ \exists m {\leq} t.~ \forall t'{\geq} m.~ t'\not\in \pi \}$
  - $\pi$ is safety if, within any trace $t$ that violates $\pi$,
     there exists a finite "bad prefix" $m$ that can only be extended
     to traces $t'$ that also violate $\pi$

- {.fragment} $\pi_{\square\lnot\alpha} = \{t ~|~ \alpha \not\in t \} \in \mathtt{Safety}$
  [//]: <> ( - Program should never cause bad event $\alpha$. )
  - $t \not\in \{t ~|~ \alpha \not\in t\} \iff \alpha {\in} t \Rightarrow \exists m {=} m' {\cdot} \alpha {\cdot} \mathtt{Tbc}.~ m {\leq} t \wedge \forall t' {\geq} m.~ \alpha {\in} t'$
  
- {.fragment} $\pi_{\square\lnot \mathtt{Done}}= \{t ~|~ \mathtt{Done} \not\in t\}  \in \mathtt{Safety}$
  - Program should not terminate. Exercise: show that this is safety.

- {.fragment} $\pi_{\lozenge\alpha}^\mathtt{term} = \{ t ~|~ \mathtt{Done} \in t \Rightarrow \alpha \in t \} \in \mathtt{Safety}$
  [//]: <> ( - In every terminating trace the good event $\alpha$ must eventually happen. )
  - If program terminates without producing any $\alpha$ monitor knows that the property is violated.
    Exercise: show that $\pi_{\lozenge\alpha}^\mathtt{term}$ is safety.

- {.fragment} $\pi_{\lozenge\alpha} = \{ t ~|~ \alpha \in t \} \not\in \mathtt{Safety}$

[//]: <> ( Any trace property that allows all non-terminating traces )
[//]: <> ( is safety in our model (e.g. `\piâ–¡Â¬Done`, `\piâ‹„\alpha^term`) )
[//]: <> ( - `t` terminating if `Done \in t`, )
[//]: <> ( - `t` non-terminating if `Done \not\in t`, )
[//]: <> (   i.e. t infinite or ends with `Loop` (silent divergence) )

[//]: <> ( Q: Can safety be defined using this? )
[//]: <> ( `Safety* = {\pi \in 2^Trace | \forall t non-terminating. t \in \pi}` )
[//]: <> ( - `\pi` is `Safety*` if it allows all non-terminating traces )
[//]: <> ( A: No! `\piâ–¡Â¬\alpha` above is intuitively safety, )
[//]: <> (    but it rejects some non-terminating traces. )

## Robust Safety Property Preservation (RSP)
- RSP: `âˆ€P Ï€âˆˆSafety. P robustly sat Ï€ â‡’  Pâ†“ robustly sat Ï€`

- {.fragment} RSC: `âˆ€P Câ‚œ m. Câ‚œ[Pâ†“] â‡* m â‡’ âˆƒCâ‚›. Câ‚›[P] â‡* m`
  - where `W â‡* m â‰œ âˆƒtâ‰¥m. Wâ‡t`

- {.fragment} Theorem: `RSP â‡” RSC`. Exercise: prove this.

- {.fragment} RSP is an interesting secure compilation criterion
  - easier to achieve and prove than most other criteria
  - still quite expressive:
    code and data integrity, but not confidentiality

[//]: <> ( TODO It would be nice to show, at least by example (e.g. on our example) )
[//]: <> ( why this usually captures code and data integrity )

## Example secure compilation chain satisfying RTP/RSP

## Target abstract machine REG+IO+2â„‚

- Goal #1: to provide enough protection to enforce RTP/RSP:
  - separated memory for each component for variables and local stacks
  - protected cross-component call stack

- Goal #2: keep things simple and independent of a particular enforcement mechanism

- {.fragment} Call and Return instructions, separated components

      instr ::= ...
              | Call â„‚.P             call to component â„‚
              | Return               return to top of protected stack

      CD ::=                       component declaration (record)
       {code=instrâ‚,...,instrâ‚™,           code of all its procedures
        entry_points=Pâ‚â†¦iâ‚, ..., Pâ‚™â†¦iâ‚™}   entry point of each procedure

      Wâ‚œ ::= C.CDâ‚, P.CDâ‚‚

[//]: <> ( Non Goal (yet) to be implementable by various enforcement mechanisms? )
[//]: <> ( Without abstract variable addresses, this machine is as unimplementable )
[//]: <> ( as Yannis' one on a single address space target machine! It could be )
[//]: <> ( implemented with processes and (infinite) virtual memory. )

## Semantics of REG+IO+2â„‚

- Each component's memory fully separated from the others;
  components can't even address each other's memory 
  
  [//]: <> ( (like in PROC+IO+2â„‚) )

      Wâ‚œ âŠ¢ â„‚, M, R, PC â†’Ï„ â„‚, M, R[R_RAâ†¦PC], offset(Wâ‚œ,â„‚,l)  when Wâ‚œ[â„‚,PC] = Jal l,
      Wâ‚œ âŠ¢ â„‚, M, R, PC â†’Ï„ â„‚, M, R, R[r]                     when Wâ‚œ[â„‚,PC] = Jump r
      Wâ‚œ âŠ¢ â„‚, M, R, PC â†’Ï„ â„‚, M, R, offset_of(Wâ‚œ,â„‚,l)  when Wâ‚œ[â„‚,PC]=Bnz r l and R[r]â‰ 0
      Wâ‚œ âŠ¢ â„‚, M, R, PC â†’Ï„ â„‚, M, R, PC+1               when Wâ‚œ[â„‚,PC]=Bnz r l and R[r]=0

      Wâ‚œ âŠ¢ â„‚, M, R, PC â†’Ï„ â„‚, M, R[rdâ†¦M[â„‚,R[rp]]], PC+1  when Wâ‚œ[â„‚,PC]=Load *rp -> rd
      Wâ‚œ âŠ¢ â„‚, M, R, PC â†’Ï„ â„‚, M[â„‚,R[rp]â†¦R[rs]], R, PC+1  when Wâ‚œ[â„‚,PC]=Store rs -> *rp

- {.fragment} Cross-component calls and returns use the protected call stack `Ïƒ`:

      Wâ‚œ âŠ¢ â„‚â‚,Ïƒ,M,R,PC â†’_{Call â„‚â‚ â„‚â‚‚.P(R[R_Arg])} â„‚â‚‚, (â„‚â‚,PC+1)::Ïƒ, M, R, entry(Wâ‚œ,â„‚â‚‚,P)
        when Wâ‚œ[â„‚â‚,PC] = Call â„‚â‚‚.P and Câ‚ â‰  Câ‚‚ (also statically checked)

      Wâ‚œ âŠ¢ â„‚â‚‚, (â„‚â‚,PC'::Ïƒ), M, R, PC â†’_{Return â„‚â‚‚ â„‚â‚ R[R_Res]} â„‚â‚, Ïƒ, M, R, PC'
        when Wâ‚œ[â„‚â‚‚,PC] = Return

[//]: <> ( More final states: )
[//]: <> ( - returning on an empty stack (dynamic error, machine stops) )
[//]: <> ( - using Call with same component (statically checked) )
[//]: <> ( - TODO: any other ones? )

## Secure compiler from PROC+IO+2â„‚ to REG+IO+2â„‚

- REG+IO+2â„‚ has a lot of built-in protection
- ... so the compiler doesn't have to do that much:
  - restore more registers after calling the other component
    + `R_SP`: this one can't be saved on the stack, using a variable
    + `R_One`: just write 1 back to it
  - also restore these registers after receiving cross-component calls
    and save them before giving back control
  - keep track of whether a procedure was called by the other component

[//]: <> ( TODO: could make this more interactive, ask students why the trivial compiler doesn't work )

[//]: <> ( (â„‚, x)â†“ = Const addr_of(â„‚,x) -> R_Aux; Load *R_Aux -> R_Res )
[//]: <> ( (â„‚, x := e)â†“ = (Wâ‚›, â„‚, e)â†“; Const addr_of(â„‚,x) -> R_Aux; Store R_Res -> *R_Aux )

## Securely compiling procedures
```
(â„‚â‚, â„‚â‚‚.P(e))â†“ =
  If â„‚â‚ = â„‚â‚‚ Then
    (â„‚â‚,e)â†“; Push R_Arg; Push R_RA; Copy R_Res -> R_Arg; Jal label_of(â„‚â‚.P);
             Pop R_RA; Pop R_Arg
  Else
    (â„‚â‚,e)â†“; Push R_Arg; Push R_RA; Copy R_Res -> R_Arg;
             Const addr_of(â„‚â‚,xsp) -> R_Aux; Store R_SP -> *R_Aux;
             Call â„‚â‚‚.P;
             Const addr_of(â„‚â‚,xsp) -> R_Aux; Load *R_Aux -> R_SP;
             Pop R_RA; Pop R_Arg; Const 1 -> R_One

(â„‚.P(arg) { e })â†“ =
  Const addr_of(â„‚,xsp) -> R_Aux; Load *R_Aux -> R_SP; Const 1 -> R_One;
  (â„‚, e)â†“; Return;
  Label label_of(â„‚.P); (â„‚, e)â†“; Jump R_RA
```

## Exercise: improve compilation to not duplicate each procedure's body
~Fragment
Solution: use the stack to remember the entry point
```
(â„‚.P(arg) { e })â†“ =
  Const addr_of(â„‚,xsp) -> R_Aux; Load *R_Aux -> R_SP; Const 1 -> R_One;
  Push R_One; Bnz R_One lexp;
  Label label_of(â„‚.P); Const 0 -> R_Aux; Push R_Aux;
  Label lexp; (â„‚, e)â†“; Pop R_Aux; Bnz R_Aux lcall;
  Jump R_RA; Label lcall; Return
```
Another solution: use an extra variable.
~

## An effective proof technique for RSP

## Partial semantics

- Captures the traces of a partial program when linked with any context

- Basically context abstracted away as nondeterminism

- We can actually define this generically, given a partialization
  function on complete states $\texttt{par}(cs,\mathbb{C})$:

$$
  \frac{
    \texttt{par}(cs,\mathbb{C}) = ps \quad
    \texttt{par}(cs',\mathbb{C}) = ps' \quad
    \quad cs \xrightarrow{\alpha} cs'}{ps \xrightharpoonup{\alpha} ps'}
$$

## Proof technique for RSP (basic version)
![basic](stuff/img/rsc-diagram-basic.png)

[//]: <> ( TODO: draw this in tikz )

[//]: <> ( Basic proof diagram: https://photos.app.goo.gl/LHeti93HQUwP7f9JA )

[//]: <> ( Ingredients: )
[//]: <> ( - partial semantics: composition and decomposition lemmas )
[//]: <> ( - back-translation for finite trace prefixes )
[//]: <> ( - BCC for partial semantics (by forward simulation if target determinate) )

## Complication #1: traces might not be informative enough for back-translation

[//]: <> ( This is not just hypothetical, it happens even in our example! )

- A trace prefix may correspond to several different executions:
```
m = Input C 0; Output P 1; Output P 2; Input C 3
```
- What procedure caused what inputs and outputs in the program `P`?
  + Need to know if we want to the backtranslated context to call the correct procedure

[//]: <> ( TODO: explained on the board why this could be hard to figure out )

## Solution: track component switches via informative traces

```
Ï• ::= ...               informative events
    | Call â„‚â‚ â„‚â‚‚.P(i)     cross-component call (â„‚â‚â‰ â„‚â‚‚)
    | Ret â„‚â‚‚ â„‚â‚ i         cross-component return (â„‚â‚â‰ â„‚â‚‚)

Î¼ ::=                   informative traces
    | Ï•â‚Â·...Â·Ï•â‚™Â·Done        succesful termination
    | Ï•â‚Â·...Â·Ï•â‚™Â·Loop        silent divergence
    | Ï•â‚Â·...Â·Ï•â‚™Â·...         infinite trace

W âŠ¢ â„‚â‚, M, â„‚â‚‚.P(i) â†’_{Call â„‚â‚ â„‚â‚‚.P(i)} â„‚â‚‚, M, return â„‚â‚ e[argâ†¦i]
  when â„‚â‚‚.P(arg){e}âˆˆW and â„‚â‚â‰ â„‚â‚‚

W âŠ¢ â„‚â‚‚, M, return â„‚â‚ i â†’_{Ret â„‚â‚‚ â„‚â‚} â„‚â‚, M, i
```

- A more informative trace could for instance be:
```
Î¼ = Input C 0; Call C P.Pâ‚(0); Output P 1; Output P 2; Ret P C 0; Input C 3
```

## Proof technique with informative traces

![informative-traces](stuff/img/rsc-diagram-informative-traces.png)

[//]: <> ( New diagram (but adapted from Jeremy's setting, in which the context )
[//]: <> ( cannot cause events, so the ultimate sand-boxing): )
[//]: <> ( https://photos.app.goo.gl/gvrK1MNan5DF7VJ19 )

[//]: <> ( Note: Switching to informative traces can turn a finite trace to an )
[//]: <> ( infinite trace, in particular silent divergence to regular )
[//]: <> ( divergence. It can't turn a finite prefix into an infinite one though. )

[//]: <> ( Intuition: We are not back-translating finite traces, we are )
[//]: <> ( back-translating finite executions. )

## Backtranslation for our example

- Informative trace:
```
Î¼ = Input C 0; Call C P.Pâ‚(0); Output P 1; Output P 2; Ret P C 0; Input C 3
```
- Can ignore what happens in the program:\
  `Output P 1; Output P 2; Ret P C 0`
- Only backtranslate the events produced by the context:
```
Câ‚› = main(arg) { input; P.Pâ‚(0); input }
```

## A more complicated back-translation example
+ Informative trace
``` 
Î¼ = Call P C.Pâ‚(0); Ret C P 0; Call P C.Pâ‚(1); Call C P.main(2)
```
+ {.fragment} Back-translation:
      Câ‚› = Pâ‚(arg) { if (i == 0) then 
                       i++; 0 
                     else if (i == 1) then
                       i++; P.main(2);
                     else
                       exit
          }
+ {.fragment} We can do this informative trace-based back-translation generically

[//]: <> ( TODO It would be a great exercise to ask for another such back-translation from the students )

## Complication #2: we might want to reuse a BCC proof for whole programs

![bcc-fcc-reuse](stuff/img/rsc-diagram-bcc-fcc-reuse.png)

[//]: <> ( diagram: https://photos.app.goo.gl/ttuvKXB7N4mxmsYs8 )

[//]: <> ( TODO The BCC + Separate Compilation arrow could be exactly SCC. )
[//]: <> ( TODO The FCC + Separate Compilation arrow could be a forward variant of SCC. )

## Complication #3: interfaces and static privileges

[//]: <> ( TODO: bring in all motivation why interfaces are needed from: )
[//]: <> ( - 3.3 RSC_DC_MD : Mutually Distrustful Components (CCS) )
[//]: <> ( - or CSF'16 even )

- We want to reason only about source contexts `Câ‚›` with a
  certain interface, capturing its static privileges
  - for our languages interface = set of imported and exported procedures,
    whether input is allowed, whether output is allowed
  - target sandboxes components so they can't exceed their privileges

- {.fragment} RSP+I: `âˆ€IP. âˆ€P:IP. âˆ€Ï€âˆˆSafety. âˆ€ICâ‹ˆIP.`\
  `(âˆ€Câ‚›:IC. Câ‚›[P] sat Ï€) â‡’ (âˆ€Câ‚œ:IC. Câ‚œ[Pâ†“] sat Ï€)`

- {.fragment} RSC+I: `âˆ€IPâ‹ˆIC. âˆ€P:IP. âˆ€Câ‚œ:IC. âˆ€m.`\
  `Câ‚œ[Pâ†“] â‡* m â‡’ âˆƒCâ‚›:IC. Câ‚›[P] â‡* m`
  - our back-translation already produces `Câ‚›` satisfying the interface `IC`

- {.fragment} We assume same interfaces for source and target languages

[//]: <> ( TODO: work out more how interfaces look in our compilation chain, )
[//]: <> (       actually do the extension )

[//]: <> ( TODO: show that RSP+I â‡” RSC+I )

[//]: <> ( TODO: this becomes more interesting for mutually distrustful )
[//]: <> (       components written in unsafe source language )

## Robust Dense Property Preservation (RDP)
- The role of liveness is taken in our trace model by **dense properties**
  - in particular, in our model any trace property can be decomposed as the
    intersection of a safety property and a dense property
- {.fragment} `Dense â‰œ {Ï€ âˆˆ 2^Trace | âˆ€t terminating. t âˆˆ Ï€}`
  - `Ï€` is `Dense` if it allows all terminating traces
  - i.e. it can only be violated by non-terminating traces
- {.fragment} RDP: `âˆ€P Ï€âˆˆDense. P robustly sat Ï€ â‡’  Pâ†“ robustly sat Ï€`
- {.fragment} RDC: `âˆ€P. âˆ€Câ‚œ. âˆ€t non-terminating. Câ‚œ[Pâ†“]â‡t â‡’ âˆƒCâ‚›. Câ‚›[P]â‡t`
- {.fragment} No known (infinite) trace-based technique for proving RDC

## Robust Hyperproperties Preservation

- RTP requires preserving code and data integrity, but not confidentiality

- {.fragment} RHP implies preserving **data confidentiality** (e.g. noninterference)

- {.fragment} Trace properties are properties of individual traces (`Ï€ âˆˆ 2^Trace`);\
  Hyperproperties relate multiple runs of a program (`H âˆˆ 2^2^Trace`)

- {.fragment} `W sat Ï€ â‰œ âˆ€t. Wâ‡t â‡’ tâˆˆÏ€     ` `     W sat H â‰œ {t | Wâ‡t} âˆˆ H`

- {.fragment} RHP: `âˆ€P Hâˆˆ2^2^Trace. P robustly sat H  â‡’  Pâ†“ robustly sat H`

- {.fragment} RHC: `âˆ€P Câ‚œ. âˆƒCâ‚›. âˆ€t. Câ‚œ[Pâ†“] â‡ t â‡” Câ‚›[P] â‡ t`
  - quantifiers swapped, trace-based back-translation no longer possible
  - `â‡’` from RTC turned into `â‡”` in RHC (no refinement of nondeterminism)

## Robust Relational Hyperproperties Preservation

<!-- Recall that: -->
<!-- - RHP implies preserving **data confidentiality** (e.g. noninterference) -->
<!-- - Hyperproperties relate multiple runs of a single program\ -->

- Preserving **data and code confidentiality**
  - but code confidentiality hopeless with side-channels

- {.fragment} Relational hyperproperties relate multiple runs of **different** programs
  (e.g. trace equivalence relates the runs of 2 programs)

- {.fragment} R2rHP: `âˆ€Pâ‚ Pâ‚‚ Râˆˆ2^(2^TraceÃ—2^Trace).(âˆ€Câ‚›.({t|Câ‚›[Pâ‚]â‡t},{t|Câ‚›[Pâ‚‚]â‡t})âˆˆR) â‡’ (âˆ€Câ‚œ.({t|Câ‚œ[Pâ‚â†“]â‡t},{t|Câ‚œ[Pâ‚‚â†“]â‡t})âˆˆR)`

- {.fragment} R2rHC: `âˆ€Pâ‚ Pâ‚‚ Câ‚œ. âˆƒCâ‚›. (âˆ€t. Câ‚œ[Pâ‚â†“] â‡ t â‡” Câ‚›[Pâ‚] â‡ t)`\
  `âˆ§ (âˆ€t. Câ‚œ[Pâ‚‚â†“] â‡ t â‡” Câ‚›[Pâ‚‚] â‡ t)`

- {.fragment} this generalizes to relations of arbitrary arity, including infinite arity:
  - RrHC: `âˆ€Câ‚œ. âˆƒCâ‚›. âˆ€P. âˆ€t. Câ‚œ[Pâ†“] â‡ t â‡” Câ‚›[P] â‡ t`

## Open Research Problems

<http://prosecco.gforge.inria.fr/personal/hritcu/talks/2018-08-26-Fomally-Secure-Compilation-FOSAD-part1-intro.pdf#page=15>

[//]: <> ( return to powerpoint slide 15-16 (maybe also POPL paper and TODO.org) )
[//]: <> ( try to explain things in a bit more detail, e.g. 1 slide per probl)


# Secure Compartmentalizing Compilation for Unsafe Languages

<http://prosecco.gforge.inria.fr/personal/hritcu/talks/2018-08-26-Fomally-Secure-Compilation-FOSAD-part2-intro.pdf>

[//]: <> ( ## This is not only about C/C++ )
[//]: <> ( While C/C++ are notoriously bad in this respect, even safer languages )
[//]: <> ( have unsafe escape hatches: )
[//]: <> ( - unsafe blocks in Rust )
[//]: <> ( - Obj.magic in OCaml )
[//]: <> ( - unsafePerformIO in Haskell )
[//]: <> ( - reflection in Java/C#? )
[//]: <> ( The biggest such escape hatch for safer languages is often linking )
[//]: <> ( with unsafe low-level code (discussed in previous course) )

[//]: <> ( Software Security is a Programming Languages Issue http://www.pl-enthusiast.net/2018/08/13/security-programming-languages-issue/ )

[//]: <> ( ## last 10 min: Open Research Problems (again) )

# Table of contents

[TOC]
